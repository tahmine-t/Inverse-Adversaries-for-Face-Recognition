# Inverse Adversaries for Deep Face Recognition

## Project Overview
This project explores the use of inverse adversaries as an alternative to class prototypes in center-based face recognition methods. The goal is to improve discrimination in the latent space by enhancing intra-class compactness and inter-class dispersion of features. The project was completed as part of the final project for the Neural Networks graduate-level course under the supervision of Prof. Modjtaba Rouhani.

## Key Objectives
- Investigate the use of inverse adversaries in place of traditional class prototypes (centers) in center-based face recognition methods.
- Analyze the relationship between class prototypes, high-likelihood regions, and decision boundaries.
- Improve inter-class dispersion and intra-class compactness of features on the MNIST dataset, demonstrating the effectiveness of inverse adversaries in enhancing feature discrimination.

## Papers Studied
1. **A Discriminative Feature Learning Approach for Deep Face Recognition**  
   This paper introduces **center loss**, a method that enhances the discriminative power of deep features by minimizing the distance between features and their corresponding class centers. This approach improves the compactness of features within each class and increases the separation between classes.

2. **The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for Improving Adversarial Training**  
   This paper presents the concept of **inverse adversaries**, which are adversarial examples generated using a modified approach of Projected Gradient Descent (PGD). Instead of maximizing the loss to deceive the model, inverse adversaries minimize the loss within certain constraints, bridging the gap between adversarial examples and the high-likelihood regions of their classes.

## Methodology
1. **Data Preparation**  
   The MNIST dataset was used for training and testing the model. The dataset was split into training and test sets to ensure balanced class representation.

2. **Model Architecture**  
   The project used the TRADES model trained on the MNIST dataset. The model was optimized using cross-entropy loss for comparison with center-based loss methods and inverse adversarial training.

3. **Inverse Adversary Generation**  
   Inverse adversaries were generated by minimizing the objective function in a reverse manner compared to traditional adversary generation. These adversaries were positioned near the high-likelihood regions of the dataset to improve the model's robustness.

4. **Feature Analysis**  
   Feature prototypes were generated from both clean and adversarial images. The analysis focused on comparing the class centers generated through center loss and the inverse adversaries generated through the adversarial approach.

5. **Evaluation Metrics**  
   - **Cosine Similarity**: Used to measure the similarity between the feature centers of clean samples and adversarial samples.
   - **Mean Squared Error (MSE)**: Used to calculate the differences between clean feature centers and inverse adversary centers.

## Results
- The results showed that inverse adversaries can effectively replace traditional class centers, maintaining intra-class compactness and improving the model's robustness to adversarial perturbations.
- Using inverse adversaries, the model achieved improved feature discrimination, showing better inter-class dispersion and intra-class compactness when compared to the traditional center loss approach.

## Conclusion
This project demonstrates the potential of inverse adversaries in enhancing face recognition models. By using inverse adversaries as an alternative to class prototypes in center-based loss functions, the model's ability to discriminate between classes is significantly improved. Further exploration into this technique can potentially lead to more robust models for face recognition and other deep learning tasks.
